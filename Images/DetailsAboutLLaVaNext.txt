LLaVA-NeXT: Stronger LLMs Supercharge Multimodal Capabilities in the Wild
This blog post discusses the integration of stronger large language models (LLMs) into LLaVA-NeXT, enhancing its multimodal capabilities. [link]( https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/)

LLaVA-NeXT: Improved Reasoning, OCR, and World Knowledge
This article outlines improvements in reasoning, optical character recognition (OCR), and world knowledge in LLaVA-NeXT models. [link](https://llava-vl.github.io/blog/2024-01-30-llava-next/)

LLaVA-NeXT: A Strong Zero-shot Video Understanding Model
This publication explores LLaVA-NeXT's performance in video understanding tasks without explicit video training. [link](https://llava-vl.github.io/blog/2024-04-30-llava-next-video/)

LLaVA-NeXT: Tackling Multi-image, Video, and 3D in Large Multimodal Models
This blog post addresses LLaVA-NeXT's capabilities in handling multi-image, video, and 3D data. [link](https://llava-vl.github.io/blog/2024-06-16-llava-next-interleave/)

LLaVA-NeXT - GitHub Repository
The official GitHub repository provides access to the codebase, models, and additional documentation for LLaVA-NeXT. [link](https://github.com/LLaVA-VL/LLaVA-NeXT)
